{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain a reddit client id and secret key, visit https://www.reddit.com/prefs/apps\n",
    "Reddit secrets prefixed with: `REDDIT_`\n",
    "- `DEV_NAME` can either be your reddit username or the username of your bot\n",
    "- `BOT_USER` username of bot\n",
    "- `BOT_PASS` password of bot\n",
    "- `CLIENT_ID` application client (listed under application name)\n",
    "- `SECRET_KEY` application api key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "# os.environ[\"REDDIT_DEV_NAME\"] = \"\" \n",
    "# os.environ[\"REDDIT_BOT_USER\"] = \"\" \n",
    "# os.environ[\"REDDIT_BOT_PASS\"] = \"\" \n",
    "# os.environ[\"REDDIT_CLIENT_ID\"] = \"\" \n",
    "# os.environ[\"REDDIT_SECRET_KEY\"] = \"\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_api_key = os.environ.get('OPENAI_API_KEY')\n",
    "reddit_dev = os.environ.get('REDDIT_DEV_NAME')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup Reddit Auth Headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = f\"shell:com.example.myredditapp:v0.0.1 (by /u/{reddit_dev})\"\n",
    "auth_headers = {'User-Agent': agent}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic user authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_id = os.environ.get('REDDIT_CLIENT_ID')\n",
    "client_secret = os.environ.get('REDDIT_SECRET_KEY')\n",
    "username = os.environ.get('REDDIT_BOT_USER')\n",
    "password = os.environ.get('REDDIT_BOT_PASS')\n",
    "\n",
    "# First, authenticate and get an access token\n",
    "auth_url = 'https://www.reddit.com/api/v1/access_token'\n",
    "auth_data = {'grant_type': 'password', 'username': username, 'password': password}\n",
    "auth_response = requests.post(auth_url, headers=auth_headers, data=auth_data, auth=(client_id, client_secret))\n",
    "access_token = auth_response.json()['access_token']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have an access token, let's make a request to get information about the authenticated user\n",
    "user_url = 'https://oauth.reddit.com/api/v1/me'\n",
    "user_headers = {'Authorization': f'Bearer {access_token}', 'User-Agent': agent}\n",
    "user_response = requests.get(user_url, headers=user_headers)\n",
    "\n",
    "print(user_response.json())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create our RedditSearch Tool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "from langchain.tools import BaseTool\n",
    "\n",
    "class RedditWrapper(BaseTool):\n",
    "    name = \"RedditSearch\"\n",
    "    description = \"Useful for finding subreddits from the Reddit API\"\n",
    "\n",
    "    def _run(self, query: str) -> str:\n",
    "        \"\"\"Use the tool.\"\"\"\n",
    "        return self.search_reddit_for(query)\n",
    "\n",
    "    async def _arun(self, query: str) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"BingSearchRun does not support async\")\n",
    "\n",
    "    @tool(\"search\", return_direct=True)\n",
    "    def search_reddit_for(search_query: str, max_results: int=10):\n",
    "        \"\"\"Searches the Reddit API for the query.\"\"\"\n",
    "        url = f'https://www.reddit.com/subreddits/search.json?q={search_query}&limit={max_results}'\n",
    "\n",
    "        response = requests.get(url, headers=auth_headers)\n",
    "        res = []\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()['data']\n",
    "            for subreddit in data['children']:\n",
    "                result_row = (subreddit['data']['display_name']+\"\\t\"+\n",
    "                    subreddit['data']['name'] + \"\\t\" + \n",
    "                    subreddit['data']['url'])\n",
    "                print(result_row)\n",
    "                res.append(result_row.replace(\"\\t\", \" \"))        \n",
    "        else:\n",
    "            print(f'Request failed with status code {response.status_code}')\n",
    "        \n",
    "        return res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Test for redditSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "news\tt5_2qh3l\t/r/news/\n",
      "worldnews\tt5_2qh13\t/r/worldnews/\n",
      "newsbabes_nsfw\tt5_2e3cg0\t/r/newsbabes_nsfw/\n",
      "politics\tt5_2cneq\t/r/politics/\n",
      "Conservative\tt5_2qh6p\t/r/Conservative/\n",
      "NewsPorn\tt5_2ski5\t/r/NewsPorn/\n",
      "NewsOfTheWeird\tt5_2vmjd\t/r/NewsOfTheWeird/\n",
      "conspiracy\tt5_2qh4r\t/r/conspiracy/\n",
      "NewsAroundYou\tt5_6arjr2\t/r/NewsAroundYou/\n",
      "NewsHub\tt5_3ifah\t/r/NewsHub/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Review the following list of Redit Pages. Formatted as title id path.\\n                                             ['news t5_2qh3l /r/news/', 'worldnews t5_2qh13 /r/worldnews/', 'newsbabes_nsfw t5_2e3cg0 /r/newsbabes_nsfw/', 'politics t5_2cneq /r/politics/', 'Conservative t5_2qh6p /r/Conservative/', 'NewsPorn t5_2ski5 /r/NewsPorn/', 'NewsOfTheWeird t5_2vmjd /r/NewsOfTheWeird/', 'conspiracy t5_2qh4r /r/conspiracy/', 'NewsAroundYou t5_6arjr2 /r/NewsAroundYou/', 'NewsHub t5_3ifah /r/NewsHub/']\\n                                             What is the most relevant path for a search for: News.\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "redditSearch = RedditWrapper()\n",
    "\n",
    "llm = OpenAI(temperature=0.9)\n",
    "search_term = \"News\"\n",
    "urls = redditSearch.search_reddit_for(search_term)\n",
    "prompt = PromptTemplate(input_variables=[\"urls\", \"query\"],\n",
    "                                   template=\"Review the following list of Redit Pages. Formatted as title id path.\\n\\\n",
    "                                             {urls}\\n\\\n",
    "                                             What is the most relevant path for a search for: {query}.\\n\")\n",
    "\n",
    "prompt.format(query=search_term, urls=urls)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use redditSearch with an agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should look for a subreddit that is dedicated to news.\n",
      "Action: RedditSearch\n",
      "Action Input: News\u001b[0mnews\tt5_2qh3l\t/r/news/\n",
      "UpliftingNews\tt5_2u3ta\t/r/UpliftingNews/\n",
      "NewsPorn\tt5_2ski5\t/r/NewsPorn/\n",
      "politics\tt5_2cneq\t/r/politics/\n",
      "worldnews\tt5_2qh13\t/r/worldnews/\n",
      "NewsOfTheWeird\tt5_2vmjd\t/r/NewsOfTheWeird/\n",
      "NewsOfTheStupid\tt5_2tpr6\t/r/NewsOfTheStupid/\n",
      "conspiracy\tt5_2qh4r\t/r/conspiracy/\n",
      "Conservative\tt5_2qh6p\t/r/Conservative/\n",
      "NewsAroundYou\tt5_6arjr2\t/r/NewsAroundYou/\n",
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3m['news t5_2qh3l /r/news/', 'UpliftingNews t5_2u3ta /r/UpliftingNews/', 'NewsPorn t5_2ski5 /r/NewsPorn/', 'politics t5_2cneq /r/politics/', 'worldnews t5_2qh13 /r/worldnews/', 'NewsOfTheWeird t5_2vmjd /r/NewsOfTheWeird/', 'NewsOfTheStupid t5_2tpr6 /r/NewsOfTheStupid/', 'conspiracy t5_2qh4r /r/conspiracy/', 'Conservative t5_2qh6p /r/Conservative/', 'NewsAroundYou t5_6arjr2 /r/NewsAroundYou/']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should look for a subreddit that is dedicated to news and is highly active.\n",
      "Action: RedditSearch\n",
      "Action Input: News sort:top\u001b[0mworldnews\tt5_2qh13\t/r/worldnews/\n",
      "conspiracy\tt5_2qh4r\t/r/conspiracy/\n",
      "AskReddit\tt5_2qh1i\t/r/AskReddit/\n",
      "funny\tt5_2qh33\t/r/funny/\n",
      "Showerthoughts\tt5_2szyo\t/r/Showerthoughts/\n",
      "thanosdidnothingwrong\tt5_gxikd\t/r/thanosdidnothingwrong/\n",
      "LifeProTips\tt5_2s5oq\t/r/LifeProTips/\n",
      "PewdiepieSubmissions\tt5_3m0tc\t/r/PewdiepieSubmissions/\n",
      "help\tt5_2qh4a\t/r/help/\n",
      "Enhancement\tt5_2s10b\t/r/Enhancement/\n",
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3m['worldnews t5_2qh13 /r/worldnews/', 'conspiracy t5_2qh4r /r/conspiracy/', 'AskReddit t5_2qh1i /r/AskReddit/', 'funny t5_2qh33 /r/funny/', 'Showerthoughts t5_2szyo /r/Showerthoughts/', 'thanosdidnothingwrong t5_gxikd /r/thanosdidnothingwrong/', 'LifeProTips t5_2s5oq /r/LifeProTips/', 'PewdiepieSubmissions t5_3m0tc /r/PewdiepieSubmissions/', 'help t5_2qh4a /r/help/', 'Enhancement t5_2s10b /r/Enhancement/']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The most relevant path for a search for news is /r/worldnews/.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The most relevant path for a search for news is /r/worldnews/.'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "redditSearch = RedditWrapper()\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"RedditSearch\",\n",
    "        func=redditSearch.run, \n",
    "        description=\"A Reddit Search Engine. Useful when you want to find subbreddits'\",\n",
    "    )\n",
    "]\n",
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)\n",
    "topic = \"News\"\n",
    "\n",
    "prompt = PromptTemplate(input_variables=[\"query\"],\n",
    "                                  template=\"What is the most relevant path for a search for: {query}.\\n\")\n",
    "\n",
    "agent.run(prompt.format(query=topic))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-box",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
